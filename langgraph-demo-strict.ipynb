{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict\n",
    "from typing_extensions import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4\", \n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "researcher_llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4\", \n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "recommend_llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state schema - the keeps track of the conversation history of all agents\n",
    "class AppState(TypedDict):\n",
    "    messages: list[BaseMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tavily search tool - explain how the agents can use numerous different tools\n",
    "tavily_tool = TavilySearchResults( \n",
    "    max_results=6,\n",
    "    search_depth=\"advanced\",\n",
    "    include_raw_content=True,\n",
    "    include_domains=[],  # Example domains to include\n",
    "    exclude_domains=[\"youtube.com\", \"tiktok.com\", \"reddit.com\"],  # Example domains to exclude\n",
    "    k=10\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool-calling node\n",
    "def search_tool(state: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Refines the user's vacation preferences into a specific search query and retrieves search results.\n",
    "    \n",
    "    Args:\n",
    "        state (Dict): The current state of the conversation, including messages.\n",
    "    \n",
    "    Returns:\n",
    "        Dict: The updated state with the search results appended to the messages.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    # First use LLM to refine the search query\n",
    "    refine_messages = [\n",
    "        SystemMessage(content='''\n",
    "            You are a search query specialist. Your task is to convert user vacation preferences \n",
    "            into a highly specific and targeted search query that will yield the most relevant vacation destinations.\n",
    "            Ensure the query reflects a diverse range of options (including lower and higher end destinations) \n",
    "            across various locations, and takes into account any vacation preferences mentioned.\n",
    "            Do NOT include TikTok or YouTube as part of the query or in the results.\n",
    "            Return only the final search query, with no additional commentary.\n",
    "        '''),\n",
    "        HumanMessage(content=f\"Convert this request into a specific search query: {messages[-1].content}\")\n",
    "    ]\n",
    "    refined_query = search_llm.invoke(refine_messages).content\n",
    "    \n",
    "    # Use refined query with Tavily\n",
    "    search_results = tavily_tool.invoke(\n",
    "        {\"query\": refined_query,\n",
    "        \"max_tokens\": 3000}\n",
    "    )\n",
    "    formatted_results = json.dumps(search_results, indent=2)\n",
    "    messages.append(AIMessage(content=json.dumps(formatted_results)))\n",
    "    print(f'\\n====SEARCH TOOL NODE=====\\n{formatted_results}')\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the research node\n",
    "def research(state: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyzes search results and extracts key findings about vacation destinations.\n",
    "    \n",
    "    Args:\n",
    "        state (Dict): The current state of the conversation, including messages.\n",
    "    \n",
    "    Returns:\n",
    "        Dict: The updated state with the research findings appended to the messages.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    research_messages = [\n",
    "        SystemMessage(content='''\n",
    "            You are an expert vacation planner and research analyst. Analyze the provided search results and extract key vacation \n",
    "            destinations along with detailed information about what they offer. \n",
    "            \n",
    "            For each destination, please include:\n",
    "            - **Destination Name**: The name or location of the vacation spot.\n",
    "            - **Key Features**: Unique attractions or benefits (e.g., scenic views, cultural sites, adventure activities).\n",
    "            - **Amenities & Activities**: Information on accommodations, dining, recreational activities, and local experiences.\n",
    "            - **Pros & Cons**: Brief evaluation points that can help in deciding if the destination fits various user preferences.\n",
    "            - **Actionable Tips**: Recommendations for planning a visit (e.g., best time to visit, must-see attractions, local travel tips).\n",
    "            \n",
    "            Organize your response into clear sections for each destination. Use bullet points or headings where appropriate for clarity.\n",
    "        '''),\n",
    "        *messages\n",
    "    ]\n",
    "    response = researcher_llm.invoke(research_messages)\n",
    "    print(f'\\n=====RESEARCH AGENT NODE=====\\n{response}')\n",
    "    return {\"messages\": messages + [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the explain node\n",
    "def recommend(state: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Provides professional recommendations for vacation destinations based on research findings.\n",
    "    \n",
    "    Args:\n",
    "        state (Dict): The current state of the conversation, including messages.\n",
    "    \n",
    "    Returns:\n",
    "        Dict: The updated state with the recommendations appended to the messages.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    recommendation_messages = [\n",
    "        SystemMessage(content='''\n",
    "            You are an expert vacation planner known for providing clear and professional recommendations.\n",
    "            \n",
    "            Based on the research findings provided, please perform the following tasks:\n",
    "            1. Identify and rank the top vacation destinations that best meet the user's query.\n",
    "            2. For each top destination, provide:\n",
    "                - **Destination Name**: The vacation spot's name or location.\n",
    "                - **Information**: A detailed explanation of why this destination is ideal, including unique features, amenities, and any standout attractions.\n",
    "                - **Recommendations**: Actionable tips or suggestions for planning a visit, such as the best time to travel, local must-see attractions, and any insider advice.\n",
    "                \n",
    "            Organize your response in a clear, structured format (using headings or bullet points) to ensure it is easy to understand.\n",
    "            Be as detailed and informative as necessary, as a travel agent would be when providing a recommendation to a client.\n",
    "        '''),\n",
    "        *messages\n",
    "    ]\n",
    "    response = recommend_llm.invoke(recommendation_messages)\n",
    "    print(f\"\\n=====TRAVEL AGENT NODE====={response}\")\n",
    "    return {\"messages\": messages + [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "graph = StateGraph(AppState)\n",
    "graph.add_node(\"search\", search_tool)\n",
    "graph.add_node(\"research\", research)\n",
    "graph.add_node(\"recommend\", recommend)\n",
    "\n",
    "# Define the edges\n",
    "graph.set_entry_point(\"search\")\n",
    "graph.add_edge(\"search\", \"research\")\n",
    "graph.add_edge(\"research\", \"recommend\")\n",
    "graph.add_edge(\"recommend\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your function to run the graph\n",
    "def run_conversation(user_input: str):\n",
    "    \"\"\"\n",
    "    Runs the conversation graph with the given user input.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The user's input message.\n",
    "    \n",
    "    Returns:\n",
    "        str: The final output message from the conversation.\n",
    "    \"\"\"\n",
    "    initial_state = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=user_input)\n",
    "        ]\n",
    "    }\n",
    "    output = app.invoke(initial_state)\n",
    "    return output[\"messages\"][-1].content\n",
    "\n",
    "result = run_conversation(\"Im looking for a relaxing spa vacation in a bleak desert environment\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your function to run the graph\n",
    "def run_conversation(user_input: str):\n",
    "    initial_state = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=user_input)\n",
    "        ]\n",
    "    }\n",
    "    output = app.invoke(initial_state)\n",
    "    return output[\"messages\"][-1].content\n",
    "\n",
    "result = run_conversation(\"Im looking for a relaxing spa vacation in a bleak desert environment\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
